{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 32000\n",
    "sequence_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model-64-32k-100k/ckpt/w2v_embedding_64-1'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_dir = tf.train.latest_checkpoint('./model-64-32k-100k/ckpt/') \n",
    "ckpt_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_layer = tf.keras.layers.Embedding(vocab_size,\n",
    "                                      sequence_length,\n",
    "                                      input_length=1,\n",
    "                                      name=\"w2v_embedding\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_layer.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    w2v_layer,\n",
    "])\n",
    "model.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'w2v_embedding/embeddings:0' shape=(32000, 64) dtype=float32, numpy=\n",
       "array([[ 0.0321597 ,  0.01368393, -0.02549728, ..., -0.0174865 ,\n",
       "        -0.03071706,  0.03416361],\n",
       "       [ 0.00035464,  0.02307502, -0.01652487, ...,  0.03385301,\n",
       "         0.02494711,  0.03013298],\n",
       "       [-0.01363196,  0.02859947,  0.0180531 , ..., -0.04400091,\n",
       "        -0.04487803, -0.0372056 ],\n",
       "       ...,\n",
       "       [ 0.02246389,  0.01087012, -0.03487611, ..., -0.00122337,\n",
       "        -0.02905982, -0.04636227],\n",
       "       [ 0.04016094, -0.01431141,  0.04110011, ..., -0.02397348,\n",
       "        -0.03966268,  0.00605388],\n",
       "       [-0.00015162,  0.01626218,  0.03629174, ...,  0.00712913,\n",
       "         0.04331812, -0.00718949]], dtype=float32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_layer.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.Checkpoint at 0x2bdd66c72e0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = tf.train.Checkpoint(layer=w2v_layer)\n",
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2bdd124fd90>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(ckpt_dir).assert_consumed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'w2v_embedding/embeddings:0' shape=(32000, 64) dtype=float32, numpy=\n",
       "array([[-0.02971295,  0.00410122, -0.0094048 , ...,  0.02149712,\n",
       "         0.00644837,  0.01568511],\n",
       "       [-0.2899739 , -0.02694705, -0.13824375, ...,  0.16128096,\n",
       "         0.15405932,  0.12712628],\n",
       "       [-0.1654938 ,  0.05598264,  0.0244594 , ..., -0.17019223,\n",
       "        -0.35384795,  0.14580142],\n",
       "       ...,\n",
       "       [-0.21116109, -0.5072469 ,  2.1389928 , ..., -0.7406144 ,\n",
       "         1.152412  ,  0.15577023],\n",
       "       [-0.4351952 ,  0.3172441 ,  0.8916813 , ..., -0.07095525,\n",
       "         0.547772  , -0.8520549 ],\n",
       "       [ 0.47548616, -0.36260402,  0.41800928, ...,  0.8716261 ,\n",
       "        -0.32832038, -0.88099927]], dtype=float32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_layer.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\word2vec\\\\model-64-32k-100k'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = os.path.join('..', 'word2vec', 'model-64-32k-100k')\n",
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_ds = tf.data.TextLineDataset(os.path.join(MODEL_PATH, 'metadata.tsv')).filter(\n",
    "        # ignore [UNK] token\n",
    "        lambda text: tf.cast(not tf.strings.regex_full_match(text, '\\[UNK\\]'), bool))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vocabulary size and the number of words in a sequence.\n",
    "vocab_size = 32000\n",
    "sequence_length = 64\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=vocab_size,\n",
    "        output_sequence_length=sequence_length,\n",
    "        # add vocab\n",
    "        vocabulary=tf.constant(\n",
    "            [text.numpy() for text in vocab_ds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['', '[UNK]', 'dan', 'yang', 'di'],\n",
       " ['cip', 'charly', 'channing', 'casper', 'capacity'])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorize_layer.get_vocabulary()\n",
    "vocab[:5], vocab[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(a, b):\n",
    "    a = vectorize_layer(tf.constant(a))\n",
    "    b = vectorize_layer(tf.constant(b))\n",
    "    vec_a = w2v_layer(a)\n",
    "    print(\"Vector A:\", vec_a)\n",
    "    vec_b = w2v_layer(b)\n",
    "    print(\"Vector B:\", vec_b)\n",
    "    cosine_similarities = np.dot(a, b) / (np.linalg.norm(a)* np.linalg.norm(b))\n",
    "    print(\"Similarity:\", cosine_similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector A: tf.Tensor(\n",
      "[[-0.17076534  0.09946204 -0.03591677 ...  0.63685346 -0.05752937\n",
      "   0.21611916]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " ...\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]], shape=(64, 64), dtype=float32)\n",
      "Vector B: tf.Tensor(\n",
      "[[ 0.10179348  0.22054295 -0.58075035 ...  0.20306358 -0.7312863\n",
      "   0.7635352 ]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " ...\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]], shape=(64, 64), dtype=float32)\n",
      "Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "similarity(\"jakarta\", \"ibukota\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector A: tf.Tensor(\n",
      "[[-0.3711237   0.6030821   0.5711786  ... -0.05788724  1.2050811\n",
      "   0.19838865]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " ...\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]], shape=(64, 64), dtype=float32)\n",
      "Vector B: tf.Tensor(\n",
      "[[-0.55585283  0.5244362  -0.4527037  ... -0.65651584  1.2318995\n",
      "  -0.27024126]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " ...\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]\n",
      " [-0.02971295  0.00410122 -0.0094048  ...  0.02149712  0.00644837\n",
      "   0.01568511]], shape=(64, 64), dtype=float32)\n",
      "Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "similarity(\"teman\", \"sahabat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
