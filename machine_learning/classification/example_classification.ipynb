{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instagram', 'owner', 'sticker', 'tiktok', 'twitter', 'youtube']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_name = os.listdir('./dataset')\n",
    "class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\word2vec\\\\model-128-64k-100k'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = os.path.join('..', 'word2vec', 'model-128-64k-100k')\n",
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_ds = tf.data.TextLineDataset(os.path.join(MODEL_PATH, 'metadata.tsv')).filter(\n",
    "        # ignore [UNK] token\n",
    "        lambda text: tf.cast(not tf.strings.regex_full_match(text, '\\[UNK\\]'), bool))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vocabulary size and the number of words in a sequence.\n",
    "vocab_size = 64000\n",
    "sequence_length = 128\n",
    "\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "        max_tokens=vocab_size,\n",
    "        output_sequence_length=sequence_length,\n",
    "        # add vocab\n",
    "        vocabulary=tf.constant(\n",
    "            [text.numpy() for text in vocab_ds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'tahun', 'kategori', 'tidak', 'juga', 'atau', 'ia', 'itu', 'indonesia']\n",
      "['mendivestasi', 'menavigasi', 'menandatangi', 'menagerie', 'memperijazah', 'memperberbagai', 'memoles', 'memento', 'membunuhi', 'mematok']\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorize_layer.get_vocabulary()\n",
    "print(vocab[:10])\n",
    "print(vocab[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "Input: ubah foto tersebut [UNK] stiker                                                                                                                           \n",
      "Prediction: [5.2987394e-04 6.1361090e-04 9.8994058e-01 3.1207844e-03 5.0364668e-03\n",
      " 7.5860741e-04]\n",
      "Predicted label: sticker : 0.9899406\n",
      "\n",
      "Input: download sebuah video [UNK] youtube                                                                                                                           \n",
      "Prediction: [0.00227016 0.02256915 0.01509738 0.0119985  0.02716564 0.9208991 ]\n",
      "Predicted label: youtube : 0.9208991\n",
      "\n",
      "Input: bisakah kamu mengubah foto [UNK] atas [UNK] [UNK]                                                                                                                        \n",
      "Prediction: [5.8259477e-04 5.5261641e-03 9.6953493e-01 4.6514980e-03 1.3389646e-02\n",
      " 6.3152043e-03]\n",
      "Predicted label: sticker : 0.96953493\n",
      "\n",
      "Input: dapatkah saya berbicara [UNK] owner anda [UNK] meminta bantuan                                                                                                                       \n",
      "Prediction: [9.7551281e-05 9.9896276e-01 2.3870579e-04 3.9181077e-06 4.9479695e-05\n",
      " 6.4751826e-04]\n",
      "Predicted label: owner : 0.99896276\n",
      "\n",
      "Input: download video [UNK] instagram                                                                                                                            \n",
      "Prediction: [9.8609734e-01 8.8724593e-04 4.3813001e-05 4.5493972e-03 8.3012814e-03\n",
      " 1.2079024e-04]\n",
      "Predicted label: instagram : 0.98609734\n",
      "\n",
      "Input: [UNK] saya sebuah video [UNK] tiktok                                                                                                                          \n",
      "Prediction: [6.2893070e-03 1.9545792e-05 1.4733024e-04 9.8898703e-01 3.7870964e-03\n",
      " 7.6958945e-04]\n",
      "Predicted label: tiktok : 0.988987\n",
      "\n",
      "Input: saya mempunyai link video twitter download video twitter tersebut                                                                                                                       \n",
      "Prediction: [1.2093590e-03 2.9934220e-06 4.9217466e-05 4.4024107e-03 9.9427807e-01\n",
      " 5.7942540e-05]\n",
      "Predicted label: twitter : 0.9942781\n",
      "\n",
      "Input: buat stiker                                                                                                                              \n",
      "Prediction: [0.0172867  0.02167605 0.8024082  0.05513065 0.07324997 0.03024851]\n",
      "Predicted label: sticker : 0.8024082\n",
      "\n",
      "Input: halo bagaimana kabar kamu                                                                                                                            \n",
      "Prediction: [0.10972098 0.12087276 0.06908244 0.17963988 0.16066584 0.36001813]\n",
      "Predicted label: youtube : 0.36001813\n",
      "\n",
      "Input: makan ayam goreng                                                                                                                             \n",
      "Prediction: [0.09750828 0.13712466 0.30997297 0.17710438 0.12125388 0.15703584]\n",
      "Predicted label: sticker : 0.30997297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example = [\n",
    "    \"ubah foto tersebut menjadi stiker\",\n",
    "    \"download sebuah video dari youtube\",\n",
    "    \"bisakah kamu mengubah foto di atas menjadi sticker?\",\n",
    "    \"dapatkah saya berbicara dengan owner anda untuk meminta bantuan?\",\n",
    "    \"download video dari instagram\",\n",
    "    \"unduhkan saya sebuah video dari tiktok\",\n",
    "    \"saya mempunyai link video twitter, download video twitter tersebut\",\n",
    "    \"buat stiker\",\n",
    "    \"halo bagaimana kabar kamu?\",\n",
    "    \"makan ayam goreng\"\n",
    "]\n",
    "example = tf.constant([vectorize_layer(text).numpy() for text in example])\n",
    "\n",
    "predicted = model.predict(example)\n",
    "\n",
    "for pred in predicted:\n",
    "    index = predicted.tolist().index(pred.tolist())\n",
    "    score = max(pred)\n",
    "    higest_index = pred.tolist().index(score)\n",
    "    print(\"Input:\", \" \".join([vocab[each] for each in example[index].numpy()]))\n",
    "    print(\"Prediction:\", pred)\n",
    "    print(\"Predicted label:\", class_name[higest_index], \":\", score)\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
